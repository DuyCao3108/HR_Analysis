{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# Logistic Regresison \n",
    "import statsmodels\n",
    "from  statsmodels.discrete.discrete_model import Logit\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Decision tree\n",
    "from xgboost import XGBClassifier    \n",
    "import math\n",
    "# Deeplearning\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is used to disable warning texts\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Or ignore specific warnings by category (e.g., FutureWarnings)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = os.getcwd()\n",
    "\n",
    "dictionary = pd.read_excel(os.path.join(cd, 'data_dictionary.xlsx'))\n",
    "em_sur = pd.read_csv(os.path.join(cd, 'employee_survey_data.csv'))\n",
    "gen_data = pd.read_csv(os.path.join(cd, 'general_data.csv'))\n",
    "mnger_data = pd.read_csv(os.path.join(cd, 'manager_survey_data.csv'))\n",
    "intime = pd.read_csv(os.path.join(cd, 'in_time.csv'))\n",
    "outime = pd.read_csv(os.path.join(cd, 'out_time.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gen_data['Attrition'].value_counts()\n",
    "plt.pie(\n",
    "    x= data.values,\n",
    "    labels = data.index,\n",
    "    autopct='%1.1f%%'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The attrition rate is around 16%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the label of Attrition column\n",
    "gen_data['Attrition_bool'] = gen_data['Attrition'].apply(lambda x: 1 if x == \"Yes\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing In-time and Out-time data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The in-time df contains the time each employee arrive at the office. <br>\n",
    "> The out-time df contains the time each employee leave the office. <br>\n",
    "> Combining these two df together, we can extract the total time each employee spend working at the office. This metrics can indicate the diligence  of each staff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intime = intime.rename(columns={\"Unnamed: 0\": \"EmployeeID\"})\n",
    "outime = outime.rename(columns={\"Unnamed: 0\": \"EmployeeID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the df\n",
    "intime_T = intime.T\n",
    "\n",
    "# Check for number of null value in each column: intime_T.isnull().sum().values \n",
    "# Observation: Number of null values is quite small, its ok to fill them\n",
    "\n",
    "# For each employee, fillna value according to the mode of their in-time\n",
    "for employee in intime_T:\n",
    "    value_to_fill = intime_T[employee].value_counts().sort_values(ascending=False).index[1]\n",
    "    intime_T[employee] = intime_T[employee].fillna(value_to_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for employee in intime_T:\n",
    "    datetime_data = pd.to_datetime(intime_T[employee]) # convert to datetime dtype\n",
    "    hour_data = datetime_data.dt.strftime('%H').apply(lambda x: int(x)) # get current hour, convert to integer\n",
    "    min_data = datetime_data.dt.strftime('%M').apply(lambda x: int(x)) # get current minute, convert to integer\n",
    "    data_to_return = hour_data * 60 + min_data # get current minute in day\n",
    "    intime_T[employee] = data_to_return # updatee the column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the df\n",
    "outime_T = outime.T\n",
    "\n",
    "# Check for number of null value in each column: intime_T.isnull().sum() \n",
    "# Observation: Number of null values is quite small, its ok to fill them\n",
    "\n",
    "# For each employee, fillna value according to the mode of their in-time\n",
    "for employee in outime_T:\n",
    "    value_to_fill = outime_T[employee].value_counts().sort_values(ascending=False).index[1]\n",
    "    outime_T[employee] = outime_T[employee].fillna(value_to_fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for employee in outime_T:\n",
    "    datetime_data = pd.to_datetime(outime_T[employee]) # convert to datetime dtype\n",
    "    hour_data = datetime_data.dt.strftime('%H').apply(lambda x: int(x)) # get current hour, convert to integer\n",
    "    min_data = datetime_data.dt.strftime('%M').apply(lambda x: int(x)) # get current minute, convert to integer\n",
    "    data_to_return = hour_data * 60 + min_data # get current minute in day\n",
    "    outime_T[employee] = data_to_return # updatee the column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "office_time_spent = outime_T - intime_T # get the time spent\n",
    "office_time_spent = office_time_spent.iloc[1:,:] # delete the employeeID row\n",
    "agg_time_spent = pd.DataFrame(office_time_spent.T.mean(axis=1),columns=['Time_spent']) # get the mean of time spent\n",
    "agg_time_spent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate all variables in one data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio dataframe\n",
    "gen_data_new = pd.concat([gen_data,agg_time_spent],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_data = gen_data_new[['Time_spent', 'Age','DistanceFromHome','MonthlyIncome','NumCompaniesWorked',\n",
    "                           'PercentSalaryHike','TotalWorkingYears','TrainingTimesLastYear',\n",
    "                           'YearsAtCompany','YearsSinceLastPromotion','YearsWithCurrManager',\n",
    "                           'Attrition_bool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = em_sur.merge(gen_data, on='EmployeeID').merge(mnger_data, on='EmployeeID')\n",
    "likert_data = merged_df[['JobInvolvement','JobLevel','JobSatisfaction','EnvironmentSatisfaction',\n",
    "                        'WorkLifeBalance','PerformanceRating','Attrition_bool']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function performing Logistic Regression and outputing coeff table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_ratio(df):\n",
    "    dict = {}\n",
    "    for var in df.drop(columns = 'Attrition_bool'):\n",
    "        data = df[[var,'Attrition_bool']].dropna()\n",
    "        # get x, y\n",
    "        x = data[var].values\n",
    "        y = data['Attrition_bool'].values\n",
    "        # standardize \n",
    "        x = (x - x.mean()) / (x.std())\n",
    "        x = np.expand_dims(x,axis=-1)\n",
    "        # fit the model\n",
    "        model = LogisticRegression().fit(x,y)\n",
    "        coeff = model.coef_\n",
    "        coeff = np.squeeze(coeff,axis=1)\n",
    "        dict[var] = coeff\n",
    "        # gen result df\n",
    "        res_df = pd.DataFrame(dict).T.rename(columns={0: \"Coefficient\"})\n",
    "        res_df['Absolute_val'] = res_df.apply(lambda x: np.abs(x))\n",
    "        res_df = res_df.sort_values('Absolute_val',ascending=False)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Execute Logistic Regession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    \"RATIO DATA COEFF\", logit_ratio(ratio_data),\n",
    "    \"LIKERT - INTERVAL DATA COEFF\", logit_ratio(likert_data)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulize and analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_df = pd.concat([logit_ratio(ratio_data),logit_ratio(likert_data)]).sort_values('Absolute_val',ascending=True) # concat to 1 df and sort "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='white')\n",
    "fig, ax = plt.subplots(figsize =(7,7))\n",
    "# color map edit\n",
    "cm = ['#FF8080'] * len(vis_df.index)\n",
    "cm[3] = cm[4] = cm[7] = cm[14] = '#CDFAD5'\n",
    "\n",
    "ax.barh(\n",
    "    y = vis_df.index,\n",
    "    width = vis_df['Absolute_val'],\n",
    "    color = cm\n",
    ")\n",
    "\n",
    "# annotate\n",
    "for var_name, var_val in vis_df.iterrows():\n",
    "    ax.annotate(\n",
    "        str(var_val['Coefficient'])[:5],\n",
    "        xy = (var_val['Absolute_val'] + 0.01, var_name),\n",
    "        va='center',ha='left', fontweight = 'medium'\n",
    "    )    \n",
    "\n",
    "# title and labels\n",
    "ax.set_yticklabels(vis_df.index ,fontweight = 'medium')\n",
    "ax.set_title(\n",
    "    \"Factors' Coefficience\",\n",
    "    fontsize = 15,\n",
    "    fontweight = 'bold'\n",
    ")\n",
    "\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observations:\n",
    "> <ol>\n",
    "> - Tenure has the biggest effect on the attrition rate. Variables that indicate employees' tenure include: 'Total Working Years', 'Years with current manager', 'Years at company', even > 'Age'. This result indicates that the longer employees stick to this firm, the less likely they are fired or leaving the company on themselves. <br>\n",
    "> - Oddly, the longer time employees spend on office a day, the more likely they leave the position. Coefficience for 'Time spent' variable is 0.498, among the most predictive factors. <br>\n",
    "> - Satisfaction is very important. Factors such as 'Employee satisfaction', 'Environment satisfaction', 'Worklife balance' have notable effect on Attrition rate.<br>\n",
    "> - On the opposite, physical value like promotion, monthly income do not influence much on Attrition rate.  <br>\n",
    "> </ol>\n",
    "> Next step:\n",
    "> We will continue evaluating these relationships using feature importance extracted from decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate feature importance (Excluding Categorical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input\n",
    "ratio_data['EmployeeID'] = range(1,len(ratio_data)+1) # create key to merge\n",
    "likert_data['EmployeeID'] = range(1,len(likert_data)+1) # create key to merge\n",
    "\n",
    "data = ratio_data.merge(likert_data, on = 'EmployeeID')\n",
    "data = data.drop(columns=['EmployeeID', \"Attrition_bool_x\"]).rename(columns={'Attrition_bool_y': \"Attrition_bool\"}) # merge / drop / rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "x = data.drop(columns='Attrition_bool')\n",
    "y = data['Attrition_bool']\n",
    "# split to train and test\n",
    "split_n = math.floor(len(data) * 0.8)\n",
    "xtrain = x.iloc[:split_n, :]\n",
    "ytrain = np.expand_dims(y[:split_n].values,axis=-1)\n",
    "xtest = x.iloc[split_n:, :]\n",
    "ytest = np.expand_dims(y[split_n:].values,axis=-1)\n",
    "\n",
    "\n",
    "# build model\n",
    "model = XGBClassifier()\n",
    "# train model\n",
    "model.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    eval_set=[(xtest, ytest)],\n",
    "    verbose = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "feature_names = data.drop(columns='Attrition_bool').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance dataframe - All variables\n",
    "feature_importance = model.feature_importances_\n",
    "feature_importance_list = [[fi] for fi in list(feature_importance)]\n",
    "feature_names = data.drop(columns='Attrition_bool').columns\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importance_list))\n",
    "feature_importance_df = pd.DataFrame(feature_importance_dict).T.reset_index().rename(columns={0: \"Importance\", \"index\": \"Variable\"}).sort_values('Importance')\n",
    "# Plot feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.barh(\n",
    "    feature_importance_df['Variable'], \n",
    "    feature_importance_df['Importance'],\n",
    "    color = \"#7A9D54\"\n",
    "    )\n",
    "##  Annotating\n",
    "for index, row in feature_importance_df.iterrows():\n",
    "    ax.annotate(\n",
    "        str(row['Importance'])[:5],\n",
    "        xy = (row['Importance'],row['Variable'])\n",
    "    )\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xlabel(\"Importance scores\")\n",
    "ax.set_ylabel('Variable')\n",
    "ax.set_title(\n",
    "    \"\"\"\n",
    "    FEATURE IMPORTANCE\n",
    "    Excluding Categorial Variables\n",
    "    \"\"\",\n",
    "    fontsize = 15, \n",
    "    fontweight = \"bold\"\n",
    ")\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observations:\n",
    "> <ol>\n",
    "> - Again, Tenure has the biggest effect on the attrition rate, as indicated by the coefficience of factor 'Total Working Years'. <br>\n",
    "> - Unusually, extracted feature importance demonstrates that 'Years since last promotion' and 'Job involvement' are 2 influential factors. <br>\n",
    "> - Overall, result from feature improtance obtained through decision tree has similar trend with that of Logistic regresison. <br>\n",
    "> </ol>\n",
    "> Next step: We will add in the decision tree model new Categorical features to see their importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate feature importance (Including Categorical data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input\n",
    "categorical_data = gen_data[['BusinessTravel','Education','Department','EducationField','Gender','JobRole','MaritalStatus','Over18']]\n",
    "\n",
    "ratio_data['EmployeeID'] = range(1,len(ratio_data)+1) # create key to merge\n",
    "likert_data['EmployeeID'] = range(1,len(likert_data)+1) # create key to merge\n",
    "categorical_data['EmployeeID'] = range(1,len(ratio_data)+1) # create key to merge\n",
    "\n",
    "data = ratio_data.merge(likert_data, on = 'EmployeeID').merge(categorical_data, on = 'EmployeeID')\n",
    "data = data.drop(columns=['EmployeeID', \"Attrition_bool_x\"]).rename(columns={'Attrition_bool_y': \"Attrition_bool\"}) # merge / drop / rename\n",
    "data = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()\n",
    "# get data\n",
    "x = data.drop(columns='Attrition_bool')\n",
    "y = data['Attrition_bool']\n",
    "# split to train and test\n",
    "split_n = math.floor(len(data) * 0.8)\n",
    "xtrain = x.iloc[:split_n, :]\n",
    "ytrain = np.expand_dims(y[:split_n].values,axis=-1)\n",
    "xtest = x.iloc[split_n:, :]\n",
    "ytest = np.expand_dims(y[split_n:].values,axis=-1)\n",
    "# trainn model\n",
    "model.fit(\n",
    "    xtrain,\n",
    "    ytrain,\n",
    "    eval_set=[(xtest, ytest)],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "feature_names = data.drop(columns='Attrition_bool').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance dataframe - All variables\n",
    "feature_importance = model.feature_importances_\n",
    "feature_importance_list = [[fi] for fi in list(feature_importance)]\n",
    "feature_names = data.drop(columns='Attrition_bool').columns\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importance_list))\n",
    "feature_importance_df = pd.DataFrame(feature_importance_dict).T.reset_index().rename(columns={0: \"Importance\", \"index\": \"Variable\"}).sort_values('Importance')\n",
    "# Plot feature importance\n",
    "fig, ax2 = plt.subplots(figsize=(10, 13))\n",
    "ax2.barh(\n",
    "    feature_importance_df['Variable'], \n",
    "    feature_importance_df['Importance'],\n",
    "    color = '#7A9D54'\n",
    "    )\n",
    "##  Annotating\n",
    "for index, row in feature_importance_df.iterrows():\n",
    "    ax2.annotate(\n",
    "        str(row['Importance'])[:5],\n",
    "        xy = (row['Importance'] + 0.001,row['Variable']),\n",
    "        va = 'center', ha='left'\n",
    "    )\n",
    "ax2.set_xticklabels([])\n",
    "ax2.set_xlabel(\"Importance scores\")\n",
    "ax2.set_ylabel('Variable')\n",
    "ax2.set_title(\n",
    "    \"\"\"\n",
    "    FEATURE IMPORTANCE \n",
    "    Including Categorical Variable \n",
    "    \"\"\", \n",
    "    fontsize = 15, \n",
    "    fontweight = \"bold\"\n",
    ")\n",
    "sns.despine()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Lets explore the 'EducationField_Marketing' and 'MaritalStatus_Single' features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fucntion help calculate and visulize relationship between categorical variables \n",
    "from sklearn.metrics import confusion_matrix\n",
    "def explore_cate_data(cat_var):\n",
    "    cm = confusion_matrix(data[cat_var], data['Attrition_bool'])\n",
    "    attrition_rate = cm[1,1] / cm[1,0]\n",
    "    \n",
    "    sns.heatmap(cm, cmap=\"viridis\")   \n",
    "    ax = plt.gca()\n",
    "    ax.set_xlabel('Attrition_bool')\n",
    "    ax.set_ylabel(cat_var)\n",
    "\n",
    "    print(f'When {cat_var} is true, attrition rate is {attrition_rate}')\n",
    "    print(cm)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_cate_data('EducationField_Marketing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There is no obvious relationship between employees coming from Marketing field and their attrition rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_cate_data('MaritalStatus_Single')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When the marital status of employees is single, there is 34% chance they will leave the company on the next year. <br>\n",
    "> This number is nearly double the average attrition rate, which is 15%. <br>\n",
    "> \n",
    "> <strong> This result indicates that a un-married employee has a higher chance of quiting or being fired. <br> </strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the Company's Perspective:**\n",
    "\n",
    "- **Reward System for Tenure:** Data demonstrates the significant influence of tenure on attrition rates. When an employee's total working years with the company increase by 1, the likelihood of them leaving the organization decreases by a substantial 11.69%.\n",
    "- **Emphasizing Employee Satisfaction:** The findings also underscore the crucial role of employee satisfaction in relation to job contentment, work environment, and work-life balance. To effectively mitigate attrition, the company should prioritize initiatives aimed at enhancing employee satisfaction.\n",
    "\n",
    "**From the Employee's Perspective:**\n",
    "\n",
    "- **Consider Avoiding Candidates with a High Company-Change Rate:** It's important to take into account an applicant's history of frequent company changes, as this factor has a positive correlation with attrition rates.\n",
    "- **Preference for Married Candidates:** Of noteworthy concern is the attrition rate among single employees, with approximately 1/3 of them having left the company in the previous year. This figure is double the average attrition rate, suggesting a preference for candidates in marital relationships may be beneficial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
